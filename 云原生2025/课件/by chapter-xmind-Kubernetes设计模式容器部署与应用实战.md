# Kubernetes设计模式
容器部署与应用实战

## 第一章：引言与云原生基础

### 核心问题一：如何现代化地构建与交付应用？

- 场景描述: 我的单体应用更新缓慢、扩展困难，牵一发而动全身。

- 解决方案：拥抱云原生与微服务

	- 引入微服务架构，将复杂系统分解为独立、专注的服务。

	- 讲解云原生之路：这是一种构建和运行应用程序的新方法，涉及思想、文化和流程的全面升级。

	- 关联实验: (第一、二周) 思考自身业务如何进行微服务拆分。

### 核心问题二：如何标准化地打包与运行微服务？

- 场景描述: 我的Java服务在本地运行正常，但到测试环境就因JDK版本或依赖问题失败。

- 解决方案：容器化技术

	- 引入容器(Container)作为标准交付单元，实现“一次构建，到处运行”。

	- 关联实验: (第二周) 编写Dockerfile，将一个简单应用打包成Docker镜像并运行。

### 核心问题三：如何自动化地管理成百上千的容器？

- 场景描述: 我的微服务被打包成了几十个容器，如何管理它们的生命周期、网络、伸缩和故障恢复？

- 解决方案：Kubernetes容器编排

	- 引入Kubernetes作为容器编排的事实标准。

	- 核心抽象(Primitives):

		- Pod: 运行容器的原子单元。

		- Service: 提供稳定的网络访问入口。

		- 标签(Labels): 用于组织和选择资源。

		- 命名空间(Namespaces): 提供逻辑隔离。

	- 关联实验: (第三周) 使用`kubectl`创建并检查Pod、Service等基本资源。

### 《实战》结合

- Kubernetes架构图解（Master/Node组件）→ 《项目1-部署Kubernetes集群.pptx》P27 

- containerd与Kubernetes关系 → 《项目1》P5（知识点1-2） 

- 云原生核心价值（弹性、可观测性、韧性）→ 《项目1》P5-P8

- 微服务架构演进路径（单体→SOA→微服务）→ 《项目9-部署项目到Kubernetes集群.pptx》P4

- containerd安装步骤 → 《项目1》P12（技能目标8） 

- 容器运维命令（crictl）→ 《项目1》P9

- 容器镜像分层原理 → 《项目5-配置数据存储.pptx》P8

- Dockerfile多阶段构建 → 《项目10-构建企业级DevOps云平台.pptx》P15

- Pod共享网络/存储特性 → 《项目2-使用集群核心资源部署服务.pptx》P6 

- Service类型对比（ClusterIP/NodePort）→ 《项目6-使用Ingress发布服务.pptx》P14 

- Pod生命周期（Init容器）→ 《项目4-调度Pod到指定节点.pptx》P18 

- 标签选择器实战 → 《项目2》P11（任务2.1.3）

## 第二章：可预测的需求

### 核心问题一：如何避免应用在共享集群中“行为失控”？

- 场景描述: 一个应用内存泄漏，占满了服务器所有内存，导致节点上所有其他应用崩溃。

- 解决方案：声明资源需求与限制 (Predictable Demands)

	- 区分可压缩资源(CPU)与不可压缩资源(Memory)。

	- 资源请求(Requests): 调度时所需，保证Pod能获得至少这么多资源。

	- 资源限制(Limits): 运行时强制约束，防止资源滥用。

	- 服务质量(QoS)等级: Guaranteed, Burstable, Best-Effort，决定了Pod在资源紧张时的“待遇”。

	- 关联实验: (第四、五周) 部署不同QoS等级的Pod，观察资源耗尽时谁先被驱逐。

### 核心问题二：如何对不同团队或环境进行资源配额管理？

- 场景描述: 作为集群管理员，我如何防止开发团队用光整个集群的资源，并为生产环境预留足够的资源？

- 解决方案：命名空间级的资源治理

	- ResourceQuota: 限制一个命名空间内的资源总量和对象数量。

	- LimitRange: 为命名空间内的Pod设置默认的、最小/最大的资源请求与限制。

	- 关联实验: (第五周) 创建一个Namespace并为其配置ResourceQuota，尝试在其中创建超出配额的Pod并观察结果。

### 《实战》结合

- 资源超限后果（OOMKilled）→ 《项目4》P10 

- HPA自动扩缩容策略 → 《项目8-使用Operator自定义控制器部署应用.pptx》P22 

- cgroup原理 → 《项目5》P7（知识点2）

- 资源配额监控 → 《项目11-使用Python管理Kubernetes集群.pptx》P13

## 第三章：声明式部署

### 核心问题一：如何实现应用的自动化、零停机更新与一键回滚？

- 场景描述: 我需要发布新版应用，要求整个过程自动化、服务不中断，并且在出问题时能快速恢复到旧版。

- 解决方案：使用Deployment进行滚动更新

	- 引入`Deployment`资源来声明应用的期望状态。

	- 讲解滚动更新(RollingUpdate)策略，通过逐个替换Pod来保证零停机。

	- 演示`kubectl rollout undo`命令，实现一键回滚。

	- 关联实验: (第六周) 创建Deployment，执行滚动更新，然后执行回滚操作。

### 核心问题二：如何实现更安全、更可控的发布策略？

- 场景描述: 对于核心业务，我不敢直接全量滚动更新。我想先让一小部分用户使用新版（金丝雀），或者准备好新版后一瞬间切换所有流量（蓝绿）。

- 解决方案：组合实现高级发布模式

	- 蓝绿部署(Blue-Green Release): 通过修改`Service`的`selector`来实现流量的瞬时切换。

	- 金丝雀发布(Canary Release): 通过维护两个不同版本的`Deployment`并由同一个Service代理来实现流量按比例切分。

	- 关联实验: (第七周) 手动模拟蓝绿部署和金丝雀发布的流程。

### 《实战》结合

- Deployment滚动更新流程 → 《项目6》P21

- ResourceQuota配置示例 → 《项目3-认证授权用户访问集群资源.pptx》P8 

- GitOps实践（Argo CD）→ 《项目10》P18

- 配置漂移防护 → 《项目7-使用Helm包管理工具部署应用.pptx》P12

- Ingress灰度发布配置 → 《项目6》P24 

- Helm部署MySQL案例 → 《项目7》P7 

- 金丝雀发布流量切分 → 《项目6》P16（图6-3） 

- 回滚的etcd数据版本管理 → 《项目5》P15

## 第四章：健康度探针

### 核心问题：如何让K8s真正了解我的应用是否“健康”，并实现故障自愈？

- 场景描述: 我的应用进程还在，但内部已死锁，无法响应。K8s却认为它正常，导致问题恶化。

- 解决方案：配置精细化的健康探针 (Health Probe)

	- 就绪探针(Readiness Probe): 回答“能否接客？”。用于控制Pod是否加入服务负载均衡。

	- 存活探针(Liveness Probe): 回答“是否还活着？”。用于判断是否需要重启Pod。

	- 启动探针(Startup Probe): 专用于保护启动缓慢的应用，防止在初始化完成前被误杀。

	- 关联实验: (第八、九周) 为应用配置三种探针，模拟故障并观察K8s的自动摘流和重启行为。

### 《实战》结合

- 就绪探针（Readiness）作用 → 《项目6》P25 

- 启动探针（Startup）配置 → 《项目8》P28

- 探针超时设置 → 《项目4》P20

- 故障注入测试方法 → 《项目9》P12

## 第五章：生命周期管理

### 核心问题：在Pod被终止时，如何让我的应用“死得其所”，完成清理工作？

- 场景描述: Pod被删除时，正在处理的请求失败，数据库连接未关闭，留下了脏数据。

- 解决方案：干预Pod的生命周期 (Managed Lifecycle)

	- 理解`SIGTERM`信号，这是K8s给予的“准备关闭”的通知。

	- 使用`preStop`生命周期钩子，在Pod被杀死前执行一个自定义的清理脚本或HTTP请求，实现优雅停机。

	- 关联实验: (第十周) 部署带`preStop`钩子的Pod，观察并验证其在删除过程中的等待和清理行为。

### 《实战》结合

- PreStop钩子优雅停机 → 《项目5》P20 

- SIGTERM信号处理 → 《项目4》P18

- PodDisruptionBudget（PDB）→ 《项目8》P24

- 数据库连接释放实践 → 《项目9》P18

## 第六章：容器的自动调度

### 核心问题：如何根据复杂的业务需求，将Pod精确地调度到最合适的节点？

- 场景描述: 我的应用有的需要GPU，有的副本间必须隔离，有的需要和缓存部署在一起。

- 解决方案：高级调度策略 (Automated Placement)

	- 节点亲和性(Node Affinity): 让Pod“喜欢”某些特性的节点。

	- Pod间亲和性/反亲和性(Pod Affinity/Anti-Affinity): 定义Pod之间的聚合或分散关系。

	- 污点与容忍度(Taints and Tolerations): 让节点“排斥”不匹配的Pod，实现专用节点。

	- 关联实验: (第十一、十二周) 综合运用这些调度规则，解决一个复杂的应用布局问题。

### 《实战》结合

- 节点亲和性配置 → 《项目4》P15 

- 污点容忍度用例 → 《项目4》P12

- 拓扑分布约束 → 《项目4》P18

- GPU节点隔离策略 → 《项目4》P22

- 调度器过滤/打分机制 → 《项目4》P10 

- 多维度调度优化 → 《项目4》P22

- Descheduler负载均衡 → 《项目4》P24

- 成本优化调度 → 《项目11》P18

- 集群搭建

	- kubeadm高可用集群 → 《项目1》P20

	- 证书轮换（cert-manager）→ 《项目3》P15

	- 集群网络方案对比 → 《项目1》P25

	- 灾备恢复策略 → 《项目5》P22

## 第七章：行为模式 (综合)

### 批量与周期性作业 (Job & CronJob)

- 核心问题: 如何用K8s管理那些“一次性”或“定时”的离线任务？

- 解决方案:

	- `Job`资源: 用于确保一次性任务成功执行到完成。

	- `CronJob`资源: 如同高可用的分布式crontab，用于周期性地触发Job。

	- 关联实验: (第十三周) 创建Job和CronJob来执行脚本任务。

### 守护与单例服务 (DaemonSet & Singleton)

- 核心问题: 如何在每个节点上部署一个守护进程？如何保证集群中某个服务只有一个实例？

- 解决方案:

	- `DaemonSet`: 用于在每个（或部分）节点上运行一个Pod副本（如日志收集Agent）。

	- `StatefulSet` (replicas=1): 用于实现强一致性的单例服务。

	- 关联实验: (第十四周) 部署一个`DaemonSet`和一个单例`StatefulSet`。

### 无状态与有状态服务 (Stateless & Stateful)

- 核心问题: `Deployment`和`StatefulSet`我到底该用哪个？它们的根本区别是什么？

- 解决方案:

	- 无状态服务 (`Deployment`): 用于可任意替换的实例（“牛群”），通过普通Service负载均衡。

	- 有状态服务 (`StatefulSet`): 用于具有唯一身份、独立存储和有序启停的实例（“宠物”），需配合Headless Service和volumeClaimTemplates。

	- 关联实验: (第十五周) 对比部署`Deployment`和`StatefulSet`在网络和存储上的行为差异。

### 服务发现 (Service Discovery)

- 核心问题: 集群内的服务如何互相通信？如何将服务安全地暴露给外部用户？

- 解决方案:

	- 内部发现: `ClusterIP` Service + DNS。

	- 外部发现: `Ingress`作为推荐的L7流量入口，配合`NodePort`或`LoadBalancer`类型的Service。

	- 关联实验: (第十六周) 配置Ingress将内部服务按路径规则暴露到外部。

### 自我感知 (Self Awareness)

- 核心问题: Pod内的应用如何能知道自己的名字、IP地址等环境信息？

- 解决方案:

	- 使用 Downward API 将Pod的元数据作为环境变量或文件注入到容器中。

	- 关联实验: (综合项目) 在应用日志中打印出通过Downward API获取的Pod名称。

### 《实战》结合

- 任务作业

	- CronJob表达式语法 → 《项目2》P25

	- Job失败重试策略 → 《项目11》P13

	- 并行任务控制（Indexed）→ 《项目2》P27

	- 历史记录清理 → 《项目7》P15

- 守护服务

	- DaemonSet滚动更新 → 《项目8》P20

	- 节点污点协同策略 → 《项目8》P14

	- Redis集群槽位分配 → 《项目8》P26

	- 基础设施节点管理 → 《项目8》P18

- 有状态服务

	- PV生命周期状态 → 《项目5》P5

	- StatefulSet稳定DNS → 《项目8》P16

	- 有状态应用备份（Velero）→ 《项目5》P28

	- Headless Service原理 → 《项目8》P16  

	- MySQL主从Operator → 《项目8》P22

- DevOps实践

	- Jenkins Pipeline语法 → 《项目10》P10

	- Harbor镜像推送 → 《项目10》P8 

	- GitLab CI/CD集成 → 《项目10》P15

	- 多环境发布策略 → 《项目10》P22

