# 《Kubernetes设计模式》深度解析与实战课程教案（按周）

## 第一周: 引言与云原生基础（理论2学时）

### 1. 教学目的与要求
- 能够定义云原生应用的特征，理解从单体架构到微服务的转变
- 掌握容器和Kubernetes基本概念（Pod、服务、标签、命名空间）的概念与作用
- 通过实践初步体验容器化部署和Kubernetes环境搭建

### 2. 教学重点难点
**重点：**
- 理解云原生与容器化的基本概念，初步掌握Kubernetes的核心概念

**难点：**
- 从传统架构到云原生架构的思维转变，理解Pod作为最小部署单元的意义

### 3. 教学过程
#### (1) 导入环节：提出核心问题（15分钟）
- 提问："我有一个庞大的单体应用，每次更新都像一场灾难，牵一发而动全身，而且难以针对性地扩展某个功能。我该如何改造我的软件架构，使其在云时代更具弹性、更易维护？"
- 引导学生思考传统架构的局限性

#### (2) 新课讲授：架构的演进（45分钟）
- 引入**微服务架构**作为解决单体应用困境的思路，将复杂系统分解为一组小而专注的服务
- 讲解**云原生之路 (The Path to Cloud Native)**，阐述这不仅是技术的变革，更是思想、文化和流程的全面升级
- 展示Kubernetes架构图解（Master/Node组件）
- 讲解containerd与Kubernetes关系
- 介绍云原生核心价值（弹性、可观测性、韧性）

#### (3) 知识拓展：微服务架构演进（30分钟）
- 详细讲解微服务架构演进路径（单体→SOA→微服务）
- 分析微服务架构的优缺点
- 讨论微服务架构在云原生中的地位

### 4. 思考题及作业题
1. 思考题：传统单体架构与微服务架构各有哪些优缺点？在什么场景下应该选择微服务架构？
2. 思考题：为什么说容器是云原生应用的基石？
3. 作业题：调研一个知名互联网公司的微服务架构转型案例，分析其转型过程中遇到的挑战和解决方案

### 5. 课堂小结
通过本次课程，学生应该能够：
- 理解云原生的核心理念和价值
- 认识到微服务架构在云原生中的重要性
- 了解Kubernetes的基本架构和核心组件
- 初步掌握云原生应用的特征和设计原则

---

## 第二周: 引言与云原生基础（理论1学时, 实验1学时）

### 1. 教学目的与要求
- 理解容器化的核心概念和价值
- 掌握Docker基本操作和Dockerfile编写方法
- 能够将简单应用打包为容器镜像并运行

### 2. 教学重点难点
**重点：**
- 容器的概念与作用，Docker基本操作

**难点：**
- Dockerfile的编写和最佳实践

### 3. 教学过程
#### (1) 理论部分（45分钟）
- **导入环节**：提出核心问题（10分钟）
  - 提问："我的微服务（Java, Python, Go...）在我的开发机上能跑，但到了测试或生产环境就因为依赖、库版本不同而失败。如何才能实现'一次构建，到处运行'？"
  
- **新课讲授**：容器化基础（35分钟）
  - 引入**容器(Container)**作为现代应用的标准交付单元，它将代码和所有依赖项打包在一起
  - 讲解容器是不可变的，一旦构建，其内部环境便固定下来，确保了环境的一致性
  - 介绍容器镜像分层原理
  - 讲解Dockerfile多阶段构建

#### (2) 实验部分（45分钟）
- **动手实践**：容器化应用
  - 安装Docker环境
  - 编写一个简单的Dockerfile
  - 使用`docker build`构建镜像，并用`docker run`运行容器
  - 实践容器运维命令（crictl）

### 4. 思考题及作业题
1. 思考题：容器与虚拟机有什么区别？各有什么优缺点？
2. 作业题：选择一个简单的Web应用（如Flask、Express等），编写Dockerfile将其容器化，并提交构建过程和运行结果截图
3. 思考题：如何优化Docker镜像大小？为什么镜像大小对生产环境很重要？

### 5. 课堂小结
通过本次课程，学生应该能够：
- 理解容器化的核心价值和基本原理
- 掌握Docker的基本操作命令
- 能够编写简单的Dockerfile并构建镜像
- 了解容器镜像的分层机制和优化方法

---

## 第三周: 容器编排与资源管理初步（理论2学时）

### 1. 教学目的与要求
- 理解容器编排的必要性和Kubernetes的核心价值
- 掌握Kubernetes的基本抽象概念（Pod、Service、Labels、Namespaces）
- 初步了解资源规划的重要性

### 2. 教学重点难点
**重点：**
- Kubernetes的核心抽象概念及其关系
- 可预测的需求(Predictable Demands)概念

**难点：**
- 理解Service与Pod的关联机制
- 容量规划的思路和方法

### 3. 教学过程
#### (1) 导入环节：提出核心问题（15分钟）
- 提问："现在我有了几十个微服务的容器镜像，我该如何部署它们、在它们故障时自动重启、将它们连接成一个网络、并根据负载进行伸缩？手动管理是不可能的。"

#### (2) 新课讲授：容器编排（50分钟）
- 引入**Kubernetes**作为容器编排的事实标准
- 讲解Kubernetes的核心抽象如何解决这些管理难题：
  - **Pod:** 部署和运行容器的原子单元
  - **Service:** 为一组动态变化的Pod提供一个稳定的访问入口和负载均衡
  - **标签(Labels):** 用于组织和选择资源对象，是Service与Pod关联的纽带
  - **命名空间(Namespaces):** 用于在集群内划分逻辑隔离区

#### (3) 知识拓展：资源规划初步（25分钟）
- 提出问题："在共享的集群环境中，如果不对资源加以规划，可能会导致资源浪费或关键应用因资源不足而失败。我们该如何开始思考资源规划？"
- 引入**可预测的需求(Predictable Demands)**的概念：应用必须声明其资源需求，这是成功部署和共存的基础
- 讲解**容量规划(Capacity Planning)**的重要性，即根据所有服务的需求来规划整个集群的物理资源

### 4. 思考题及作业题
1. 思考题：为什么Kubernetes将Pod而非容器作为最小的部署单元？Pod中可以包含多个容器的设计有什么优势？
2. 作业题：设计一个简单的微服务系统，包含前端、后端API和数据库三个组件，画出其在Kubernetes中的部署架构图，标明Pod、Service和Label的使用
3. 思考题：在一个多租户的Kubernetes集群中，如何确保每个团队都能获得公平的资源分配？

### 5. 课堂小结
通过本次课程，学生应该能够：
- 理解Kubernetes的核心抽象概念及其作用
- 掌握Pod、Service、Label、Namespace的基本用法
- 认识到资源规划在容器编排中的重要性
- 初步了解Kubernetes如何解决容器编排的核心问题

---

## 第四周: 资源管理实践（理论1学时, 实验1学时）

### 1. 教学目的与要求
- 理解容器资源管理的核心概念（可压缩vs不可压缩资源）
- 掌握Docker和Kubernetes中的资源限制配置方法
- 能够通过实践观察资源限制的效果

### 2. 教学重点难点
**重点：**
- 区分可压缩资源(CPU)和不可压缩资源(Memory)的管理差异
- Kubernetes中资源请求与限制的配置方法

**难点：**
- 理解资源超限的不同后果及其处理机制
- 合理评估应用资源需求

### 3. 教学过程
#### (1) 理论部分（45分钟）
- **导入环节**：提出核心问题（10分钟）
  - 提问："如果我直接在服务器上运行一个容器，不加任何资源限制，最坏会发生什么情况？这与在Kubernetes中运行有何不同？"
  
- **新课讲授**：资源管理基础（35分钟）
  - 区分**可压缩资源(CPU)**和**不可压缩资源(Memory)**
  - 讲解当内存耗尽时，应用进程会被操作系统无情地**杀死(OOMKilled)**
  - 讲解当CPU繁忙时，应用只会被**节流(throttled)**，性能下降但不会崩溃
  - 介绍cgroup原理
  - 对比`docker run`的资源限制参数与Kubernetes的声明式资源管理

#### (2) 实验部分（45分钟）
- **动手实践**：资源限制实验
  - 使用`docker run`启动一个无内存限制的程序，并使其不断申请内存，观察容器被杀死的现象
  - 在Kubernetes中部署一个Pod，设置资源请求和限制，观察其行为
  - 对比`kubectl`和`docker`的基础命令，感受编排工具与容器运行时的区别
  - 演示资源超限后果（OOMKilled）

### 4. 思考题及作业题
1. 思考题：为什么CPU被视为"可压缩"资源而内存被视为"不可压缩"资源？这种区别对应用设计有什么影响？
2. 作业题：设计一个实验，分别测试CPU限制和内存限制对应用性能的影响，并记录观察结果
3. 思考题：在生产环境中，如何确定一个应用的合理资源请求和限制值？

### 5. 课堂小结
通过本次课程，学生应该能够：
- 理解容器资源管理的基本原理
- 掌握Docker和Kubernetes中的资源限制配置方法
- 了解资源超限的不同后果及处理机制
- 初步掌握应用资源需求评估的方法

---

## 第五周: 精细化资源管理与声明式部署（理论2学时）

### 1. 教学目的与要求
- 掌握Kubernetes中资源请求与限制的高级配置
- 理解命名空间级资源管理工具（ResourceQuota、LimitRange）
- 初步了解声明式部署的概念和价值

### 2. 教学重点难点
**重点：**
- 资源请求(Requests)和资源限制(Limits)的区别与配置
- ResourceQuota和LimitRange的使用场景

**难点：**
- 多租户环境下的资源隔离与共享策略
- 声明式部署与命令式部署的思维转变

### 3. 教学过程
#### (1) 导入环节：提出核心问题（15分钟）
- 提问："我如何向Kubernetes精确地描述我的应用：'平时需要0.5个CPU，忙时最多不能超过2个CPU；至少需要1GB内存，但绝不能超过2GB'？K8s如何利用这些信息？"

#### (2) 新课讲授：K8s资源管理核心（40分钟）
- 深入讲解**资源请求(Requests)**和**资源限制(Limits)**。`Requests`用于调度，`Limits`用于运行时强制约束
- 讲解**Pod优先级(Pod Priority)**，允许为关键应用赋予更高的调度和保留优先级
- 演示ResourceQuota配置示例
- 讲解HPA自动扩缩容策略

#### (3) 知识拓展：命名空间级资源治理（25分钟）
- 提出问题："作为集群管理员，如何防止某个项目组'挥霍无度'，用光整个集群的资源？如何为不同环境（如开发、生产）设定资源使用上限？"
- 讲解**ResourceQuota:** 限制一个命名空间内可创建的资源对象数量以及资源总量（CPU、内存）
- 讲解**LimitRange:** 为命名空间内的Pod设置默认的、最小、最大的资源请求/限制值

#### (4) 过渡：声明式部署引入（10分钟）
- 提出问题："现在我的Pod资源可控了，下一步是如何管理它们的更新和发布？"
- 引入`Declarative Deployment`模式的概念，即通过一个YAML文件"声明"应用的最终状态，由K8s负责达成
- 简介GitOps实践（Argo CD）

### 4. 思考题及作业题
1. 思考题：为什么Kubernetes将资源请求和资源限制分开配置？这种设计有什么优势？
2. 作业题：为一个多团队共享的Kubernetes集群设计资源管理策略，包括命名空间划分、ResourceQuota和LimitRange配置
3. 思考题：声明式API与命令式API相比有哪些优势？在什么场景下更适合使用声明式API？

### 5. 课堂小结
通过本次课程，学生应该能够：
- 掌握Kubernetes中资源请求与限制的配置方法和使用场景
- 理解ResourceQuota和LimitRange在多租户环境中的作用
- 了解Pod优先级对资源调度的影响
- 初步理解声明式部署的概念和价值

---

## 第六周: 声明式部署实践（理论1学时, 实验1学时）

### 1. 教学目的与要求
- 理解Kubernetes Deployment的核心机制
- 掌握滚动更新的配置和监控方法
- 能够实现应用的零停机更新和回滚

### 2. 教学重点难点
**重点：**
- Deployment资源的配置和管理
- 滚动更新策略的参数调整

**难点：**
- 理解滚动更新的内部机制
- 处理更新过程中可能出现的问题

### 3. 教学过程
#### (1) 理论部分（45分钟）
- **导入环节**：提出核心问题（10分钟）
  - 提问："我发布了应用的新版本v1.1，如何让K8s自动地、平滑地用新版本Pod替换掉所有v1.0的Pod，期间不能中断用户服务？如果新版本有问题，如何快速撤销操作？"
  
- **新课讲授**：Deployment与滚动更新（35分钟）
  - 讲解`Deployment`资源如何通过**滚动更新(RollingUpdate)**策略来实现零停机更新
  - 介绍`kubectl rollout undo`命令，作为一键回滚的"后悔药"
  - 讲解Deployment滚动更新流程
  - 介绍回滚的etcd数据版本管理

#### (2) 实验部分（45分钟）
- **动手实践**：应用发布与回滚
  - 创建一个`Deployment`资源
  - 修改`Deployment`中的镜像标签，触发一次滚动更新
  - 使用`kubectl rollout status`观察更新进度
  - 使用`kubectl rollout undo`将应用恢复到上一个版本
  - 实践Helm部署MySQL案例

### 4. 思考题及作业题
1. 思考题：滚动更新过程中，如何确保服务的连续性？`maxSurge`和`maxUnavailable`参数如何影响更新过程？
2. 作业题：设计一个实验，比较`RollingUpdate`和`Recreate`两种更新策略的区别，记录观察结果
3. 思考题：在生产环境中，如何设计一个安全的发布流程，包括测试、灰度发布和回滚机制？

### 5. 课堂小结
通过本次课程，学生应该能够：
- 理解Deployment资源的核心机制和作用
- 掌握滚动更新的配置和监控方法
- 能够实现应用的零停机更新和回滚
- 了解Helm等高级部署工具的基本用法

---

## 第七周: 高级部署策略与健康探针（理论2学时）

### 1. 教学目的与要求
- 掌握蓝绿部署和金丝雀发布等高级部署策略
- 理解健康探针的概念和作用
- 能够选择合适的部署策略应对不同场景

### 2. 教学重点难点
**重点：**
- 不同部署策略的适用场景和实现方式
- 就绪探针在部署过程中的关键作用

**难点：**
- 在复杂场景下选择和组合合适的部署策略
- 金丝雀发布的流量控制机制

### 3. 教学过程
#### (1) 导入环节：提出核心问题（15分钟）
- 提问："对于一些有破坏性变更或非常关键的服务，滚动更新（新旧版本共存）可能会带来问题。我能否先部署好新版本，测试无误后，瞬间将所有流量切换过去？（蓝绿部署）"

#### (2) 新课讲授：高级部署策略（45分钟）
- 讲解**蓝绿部署 (Blue-Green Release)**原理：同时保留新旧两套环境，通过修改`Service`的`selector`来实现流量的瞬时切换
- 提出问题："我对新版本信心不足，不敢直接全量。我能否先让一小部分用户（比如5%）使用新版本，观察其表现稳定后再逐步扩大范围？（金丝雀发布）"
- 讲解**金丝雀发布 (Canary Release)**原理：通过维护两个不同版本的`Deployment`，并调整副本数或使用更高级的流量管理工具来实现按比例的流量切分
- 演示Ingress灰度发布配置
- 讲解金丝雀发布流量切分

#### (3) 知识拓展：健康探针引入（30分钟）
- 提出问题："所有这些自动化的发布策略，都依赖一个前提：系统必须知道新启动的Pod是否真的'能工作'。这如何实现？"
- 引入`Health Probe`模式，特别是**就绪探针(Readiness Probes)**，它是决定一个Pod能否接收流量的关键
- 讲解就绪探针（Readiness）作用
- 介绍启动探针（Startup）配置
- 讲解探针超时设置

### 4. 思考题及作业题
1. 思考题：蓝绿部署和金丝雀发布各有什么优缺点？在什么场景下应该选择哪种策略？
2. 作业题：设计一个金丝雀发布方案，包括流量分配策略、监控指标和回滚机制
3. 思考题：如何结合健康探针和部署策略，构建一个更可靠的发布流程？

### 5. 课堂小结
通过本次课程，学生应该能够：
- 理解蓝绿部署和金丝雀发布的原理和实现方式
- 掌握不同部署策略的适用场景和优缺点
- 了解健康探针在部署过程中的关键作用
- 能够设计更可靠的应用发布流程

---

## 第八周: 健康探针实践（理论1学时, 实验1学时）

### 1. 教学目的与要求
- 掌握Liveness、Readiness、Startup探针的配置和使用方法
- 理解不同类型探针的适用场景
- 能够通过实践验证探针的作用

### 2. 教学重点难点
**重点：**
- 区分存活探针和就绪探针的职责和作用
- 探针参数的合理配置

**难点：**
- 针对不同应用特性选择合适的探针类型和检查方法
- 处理探针可能引发的问题（如误判、频繁重启）

### 3. 教学过程
#### (1) 理论部分（45分钟）
- **导入环节**：提出核心问题（10分钟）
  - 提问："我的应用进程还在，但内部可能已经因为死锁或依赖服务故障而无法正常工作。如何让K8s不仅检查'进程存活'，更能检查'业务健康'，并在出问题时实现故障自愈？"
  
- **新课讲授**：存活探针与就绪探针（35分钟）
  - 讲解**就绪探针(Readiness Probe):** 决定是否将Pod加入服务负载均衡。失败则摘流
  - 讲解**存活探针(Liveness Probe):** 决定Pod是否需要被重启。失败则重启
  - 介绍探针的不同实现方式：HTTP、TCP、Exec、gRPC
  - 讲解探针参数配置（initialDelaySeconds、periodSeconds等）

#### (2) 实验部分（45分钟）
- **动手实践**：健康探针配置与测试
  - 为一个`Deployment`配置好`readinessProbe`和`livenessProbe`
  - 执行一次滚动更新，观察`readinessProbe`如何确保新Pod准备好后才替换旧Pod
  - 手动模拟应用故障（如`touch /tmp/unhealthy`），让`livenessProbe`失败，观察K8s自动重启该Pod
  - 实践故障注入测试方法

### 4. 思考题及作业题
1. 思考题：为什么需要区分存活探针和就绪探针？只使用其中一种会有什么问题？
2. 作业题：为一个Web应用设计合理的健康检查策略，包括探针类型、检查路径、参数配置等，并解释设计理由
3. 思考题：如何设计探针检查逻辑，避免因为临时故障导致的频繁重启？

### 5. 课堂小结
通过本次课程，学生应该能够：
- 理解不同类型探针的作用和适用场景
- 掌握探针的配置方法和参数调整
- 能够设计合理的健康检查策略
- 了解如何通过探针实现应用的自愈能力

---

## 第九周: 探针深入与生命周期管理（理论2学时）

### 1. 教学目的与要求
- 深入理解不同类型探针的使用场景和配置方法
- 掌握Kubernetes容器生命周期事件和钩子机制
- 理解优雅停机的实现方式

### 2. 教学重点难点
**重点：**
- 区分不同类型探针的适用场景
- 生命周期钩子的配置和使用

**难点：**
- 复杂应用的探针设计
- 优雅停机的实现和调试

### 3. 教学过程
#### (1) 导入环节：提出核心问题（15分钟）
- 提问："我还是对存活探针和就绪探针感到困惑。它们都检查应用的健康，到底该在什么场景下分别使用它们？"

#### (2) 新课讲授：深入辨析探针（40分钟）
- 讲解**就绪探针**回答的是："你现在能营业吗？" (Is it ready for traffic?)。用于应用启动、依赖加载、临时过载等场景
- 讲解**存活探针**回答的是："你还活着吗？" (Is it broken?)。用于检测死锁等无法自行恢复的致命错误
- 引入**启动探针(Startup Probe)**解决启动时间过长的应用的探针配置难题
- 讨论复杂应用（如微服务）的探针设计，确保依赖项（如数据库）就绪后再接收流量

#### (3) 知识拓展：生命周期管理（35分钟）
- 提出问题："当K8s决定要终止我的Pod时，我希望应用能有机会完成当前正在处理的请求，优雅地关闭数据库连接，而不是被粗暴地'杀死'。我该如何实现这种'优雅停机'？"
- 引入**`Managed Lifecycle`**模式
- 讲解`SIGTERM`信号，这是K8s发出的"请准备关闭"的通知
- 讲解**生命周期钩子(Lifecycle Hooks)**，特别是`preStop`钩子，它是在收到`SIGTERM`信号后、容器被杀死前执行的关键回调，是实现优雅停机的最佳实践
- 介绍PreStop钩子优雅停机
- 讲解PodDisruptionBudget（PDB）

### 4. 思考题及作业题
1. 思考题：在什么情况下应该使用启动探针而非就绪探针？两者有什么区别？
2. 作业题：设计一个包含数据库连接的应用的优雅停机方案，包括preStop钩子配置和超时设置
3. 思考题：如何确保在集群维护（如节点升级）期间服务仍然可用？PodDisruptionBudget如何帮助实现这一目标？

### 5. 课堂小结
通过本次课程，学生应该能够：
- 深入理解不同类型探针的使用场景和配置方法
- 掌握容器生命周期事件和钩子机制
- 理解优雅停机的实现方式和重要性
- 了解如何通过PDB保障服务可用性

---

## 第十周: 生命周期管理实践（理论1学时, 实验1学时）

### 1. 教学目的与要求
- 掌握preStop钩子的配置和使用方法
- 理解优雅停机的实现机制
- 能够通过实践验证生命周期钩子的作用

### 2. 教学重点难点
**重点：**
- preStop钩子的配置和执行流程
- 优雅停机的实现方式

**难点：**
- 调试钩子执行失败（如超时、权限问题）
- 集群搭建和管理

### 3. 教学过程
#### (1) 理论部分（45分钟）
- **导入环节**：提出核心问题（10分钟）
  - 提问："理论上我知道了`preStop`钩子，那么在我的Pod YAML文件中，具体应该怎么写？它可以执行哪些类型的操作？"
  
- **新课讲授**：`preStop`钩子实践（35分钟）
  - 展示`preStop`钩子的两种实现方式：执行一个shell命令 (`exec`) 或发送一个HTTP GET请求 (`httpGet`)
  - 强调`preStop`是一个阻塞操作，K8s会等待它执行完成（或超时）再杀死容器
  - 讲解SIGTERM信号处理
  - 介绍数据库连接释放实践

#### (2) 实验部分（45分钟）
- **动手实践**：优雅停机验证
  - 部署一个带有`preStop`钩子的Pod，钩子内容为`sh -c 'echo "Preparing to shutdown..."; sleep 30'`
  - 执行`kubectl delete pod`，并立即用`kubectl describe pod`观察Pod状态，会看到它长时间处于`Terminating`状态，并能看到相关的事件，验证了钩子的执行
  - （选做）搭建一个简单的K8s集群（如使用kind或kubeadm）
  - 了解kubeadm高可用集群
  - 学习证书轮换（cert-manager）

### 4. 思考题及作业题
1. 思考题：为什么Kubernetes在发送SIGKILL信号前会先发送SIGTERM信号？这种设计有什么优势？
2. 作业题：设计一个实验，比较有preStop钩子和没有preStop钩子的Pod在终止时的行为差异
3. 思考题：在生产环境中，如何设计一个完整的灾备恢复策略？

### 5. 课堂小结
通过本次课程，学生应该能够：
- 掌握preStop钩子的配置和使用方法
- 理解优雅停机的实现机制和重要性
- 能够设计和实现应用的生命周期管理策略
- 了解Kubernetes集群搭建和管理的基本知识

---

## 第十一周: 容器调度基础（理论2学时）

### 1. 教学目的与要求
- 理解Kubernetes调度器的工作原理
- 掌握节点亲和性、Pod亲和性的配置方法
- 理解污点与容忍度的作用和使用场景

### 2. 教学重点难点
**重点：**
- 调度器的过滤和打分机制
- 节点亲和性与Pod亲和性的配置和使用

**难点：**
- 理解不同调度策略的组合使用
- 复杂调度需求的实现

### 3. 教学过程
#### (1) 导入环节：提出核心问题（15分钟）
- 提问："我的K8s集群里有各种各样的节点：有的CPU强，有的内存大，有的带GPU。我如何能'告诉'K8s我的Pod的偏好，让它被调度到最合适的节点上？"

#### (2) 新课讲授：容器的自动调度（45分钟）
- 讲解K8s**调度器(Scheduler)**的基本工作原理：过滤(Filtering)和打分(Scoring)
- 引入**节点亲和性(Node Affinity)**，允许Pod表达对节点特性的"喜爱"程度（必须满足或偏好满足）
- 讲解节点亲和性配置
- 介绍调度器过滤/打分机制

#### (3) 知识拓展：Pod间的关系调度（30分钟）
- 提出问题："除了节点特性，Pod之间的关系也很重要。比如，为了高可用，服务的多个副本必须分开部署；为了低延迟，应用和它依赖的缓存最好部署在一起。这又该如何实现？"
- 讲解**Pod亲和性与反亲和性(Pod Affinity/Anti-Affinity):** 定义Pod与已存在Pod之间的部署关系
- 讲解**污点与容忍度(Taints and Tolerations):** 允许节点"拒绝"不匹配的Pod，实现专用节点等场景
- 介绍污点容忍度用例
- 讲解拓扑分布约束
- 介绍GPU节点隔离策略

### 4. 思考题及作业题
1. 思考题：节点亲和性和Pod亲和性有什么区别？在什么场景下应该使用哪种？
2. 作业题：设计一个高可用的Web应用部署方案，要求应用的多个副本分布在不同的可用区，并且与其依赖的Redis缓存部署在同一个节点上
3. 思考题：如何使用污点和容忍度实现专用节点？这种方式与节点亲和性相比有什么优势？

### 5. 课堂小结
通过本次课程，学生应该能够：
- 理解Kubernetes调度器的工作原理
- 掌握节点亲和性、Pod亲和性的配置方法
- 理解污点与容忍度的作用和使用场景
- 能够设计复杂的调度策略满足不同需求

---

## 第十二周: 调度策略实践（理论1学时, 实验1学时）

### 1. 教学目的与要求
- 掌握复杂调度策略的组合使用
- 能够通过实践验证调度策略的效果
- 理解调度策略在生产环境中的应用

### 2. 教学重点难点
**重点：**
- 调度策略的组合配置
- 验证调度结果的方法

**难点：**
- 解决复杂调度需求
- 调试调度问题

### 3. 教学过程
#### (1) 理论部分（45分钟）
- **导入环节**：提出核心问题（10分钟）
  - 提问："在真实的生产环境中，一个应用可能同时有多种调度需求：它需要运行在有SSD的节点上，同时它的副本之间还要相互反亲和。如何将这些规则组合起来？"
  
- **新课讲授**：调度策略的叠加（35分钟）
  - 通过一个综合案例，展示如何在同一个Pod的YAML中同时定义`nodeAffinity`和`podAntiAffinity`
  - 讲解不同规则之间的逻辑关系（通常是"与"关系）
  - 介绍多维度调度优化
  - 讲解Descheduler负载均衡
  - 介绍成本优化调度

#### (2) 实验部分（45分钟）
- **动手实践**：综合调度策略
  - 设计一个场景：部署一个3副本的应用，要求它必须运行在`region: us-east-1`的节点上，并且3个副本必须分布在不同的`availability-zone`中
  - 学生需要为节点打上相应的标签，并编写包含`nodeAffinity`和`podAntiAffinity`的`Deployment` YAML文件来实现这一目标
  - 验证调度结果，确保Pod分布符合预期

### 4. 思考题及作业题
1. 思考题：如何设计调度策略，确保关键应用在集群资源紧张时仍能获得足够资源？
2. 作业题：设计一个包含多种调度约束的应用部署方案，并分析可能的调度结果
3. 思考题：在大规模集群中，如何优化调度性能？调度器的性能瓶颈可能在哪里？

### 5. 课堂小结
通过本次课程，学生应该能够：
- 掌握复杂调度策略的组合使用
- 能够设计和实现满足多种约束的调度方案
- 理解调度策略在生产环境中的应用和优化
- 具备调试和验证调度结果的能力

---

## 第十三周: 行为模式基础（理论2学时）

### 1. 教学目的与要求
- 掌握Job和CronJob的配置和使用方法
- 理解批处理任务和定时任务的管理模式
- 了解不同Pod管理模式的适用场景

### 2. 教学重点难点
**重点：**
- Job和CronJob的配置和管理
- 批处理任务的并行控制

**难点：**
- 复杂任务的分片与并行处理设计
- 定时任务的调度挑战

### 3. 教学过程
#### (1) 导入环节：提出核心问题（15分钟）
- 提问："我的应用场景中，除了需要7x24小时运行的在线服务，还有两种常见任务：一种是需要执行一次就结束的数据迁移脚本；另一种是需要每天凌晨定时运行的报表生成程序。如何用K8s来管理这类非长时运行的任务？"

#### (2) 新课讲授：任务型作业（45分钟）
- 讲解**`Batch Job` (批量作业):** 针对"一次性"任务，使用`Job`资源。它会创建Pod来执行任务，并确保任务成功完成（如果失败会重试），完成后Pod不会被清理（便于检查日志），`Job`对象状态变为`Completed`
- 讲解**`Periodic Job` (周期性作业):** 针对"定时"任务，使用`CronJob`资源。你只需提供一个标准的`cron`表达式和`Job`模板，`CronJob`控制器就会像一个高可用的分布式crontab一样，周期性地为你创建`Job`来执行任务
- 强调**对比:** `Job`是执行体，`CronJob`是调度器
- 介绍CronJob表达式语法
- 讲解Job失败重试策略
- 介绍并行任务控制（Indexed）
- 讲解历史记录清理

#### (3) 知识拓展：行为模式概述（30分钟）
- 简要介绍其他行为模式（如DaemonSet、StatefulSet）
- 讨论不同Pod管理模式的选择依据
- 介绍PodDisruptionBudget对高可用性的保障机制

### 4. 思考题及作业题
1. 思考题：Job和CronJob与普通的Deployment有什么本质区别？它们的控制器行为有何不同？
2. 作业题：设计一个数据处理任务，要求能够并行处理多个数据分片，并在所有分片处理完成后执行一个汇总操作
3. 思考题：如何处理CronJob可能面临的并发执行问题？不同的concurrencyPolicy设置会带来什么影响？

### 5. 课堂小结
通过本次课程，学生应该能够：
- 掌握Job和CronJob的配置和使用方法
- 理解批处理任务和定时任务的管理模式
- 了解不同Pod管理模式的适用场景
- 能够设计和实现复杂的任务处理流程

---

## 第十四周: 行为模式实践（理论1学时, 实验1学时）

### 1. 教学目的与要求
- 掌握DaemonSet和StatefulSet的配置和使用方法
- 理解守护服务和单例服务的管理模式
- 能够通过实践验证不同行为模式的特性

### 2. 教学重点难点
**重点：**
- DaemonSet和StatefulSet的配置和管理
- 守护服务和单例服务的应用场景

**难点：**
- 理解StatefulSet的唯一性和稳定性保证
- DaemonSet的更新策略

### 3. 教学过程
#### (1) 理论部分（45分钟）
- **导入环节**：提出核心问题（10分钟）
  - 提问："我需要部署一个日志收集Agent（如Fluentd）或是一个节点监控程序（如Node Exporter）。这类基础服务有一个共同特点：它们必须在集群中的**每一个**工作节点上都运行一个实例。我该如何实现这种部署模式？"
  
- **新课讲授**：守护服务与单例服务（35分钟）
  - 讲解**`Daemon Service` (守护服务)**：使用`DaemonSet`资源。它会忽略调度器，直接在所有（或匹配`nodeSelector`的）节点上创建一个Pod副本，并确保每个节点上始终有且仅有一个
  - 提出问题："我需要部署一个高可用的单例服务，比如一个集群中的主节点。它必须是唯一的，但又不能有单点故障。`StatefulSet`似乎可以，它和`DaemonSet`有什么区别？"
  - 讲解`DaemonSet`的目标是"每个节点一个"，总副本数等于节点数
  - 讲解`StatefulSet`（当`replicas=1`时）的目标是"整个集群仅一个"，实现强一致性的单例。`StatefulSet`更关注单个实例的唯一性和数据持久性
  - 介绍DaemonSet滚动更新
  - 讲解节点污点协同策略

#### (2) 实验部分（45分钟）
- **动手实践**：守护服务与单例服务
  - 部署一个简单的`DaemonSet`（如busybox），并验证每个工作节点上都有一个对应的Pod
  - 部署一个`replicas: 1`的`StatefulSet`，观察其稳定的Pod名称和PVC
  - 实践Redis集群槽位分配
  - 了解基础设施节点管理

### 4. 思考题及作业题
1. 思考题：DaemonSet和普通的Deployment有什么区别？它们的调度机制有何不同？
2. 作业题：设计一个监控系统的部署方案，包括在每个节点上运行的收集器（使用DaemonSet）和一个中央聚合服务（使用StatefulSet）
3. 思考题：为什么StatefulSet能够提供稳定的网络标识和存储？这对有状态应用有什么意义？

### 5. 课堂小结
通过本次课程，学生应该能够：
- 掌握DaemonSet和StatefulSet的配置和使用方法
- 理解守护服务和单例服务的管理模式和应用场景
- 能够设计和实现符合特定行为模式的应用部署
- 了解不同控制器的调度和管理机制

---

## 第十五周: 有状态服务管理（理论2学时）

### 1. 教学目的与要求
- 理解无状态服务和有状态服务的本质区别
- 掌握StatefulSet的高级特性和使用方法
- 了解有状态服务的存储和网络管理

### 2. 教学重点难点
**重点：**
- 无状态与有状态服务的区别和选择
- StatefulSet的存储和网络特性

**难点：**
- 有状态应用的部署和管理策略
- 持久化存储的生命周期管理

### 3. 教学过程
#### (1) 导入环节：提出核心问题（15分钟）
- 提问："在K8s中，最核心的一对概念就是无状态应用和有状态应用。我什么时候应该用`Deployment`，什么时候又必须用`StatefulSet`？它们在存储和网络方面到底有什么根本区别？"

#### (2) 新课讲授：深入对比两大核心部署模式（75分钟）
- 讲解**`Stateless Service` (无状态服务):**
  - **适用场景:** Web服务器、API网关等
  - **控制器:** `Deployment`
  - **特点:** 所有Pod完全相同，可任意替换和伸缩（"牛群"）
  - **网络:** 通过一个普通的`ClusterIP` Service提供统一入口和负载均衡
  - **存储:** 通常不直接管理持久化存储，或所有副本共享同一个PVC

- 讲解**`Stateful Service` (有状态服务):**
  - **适用场景:** 数据库、消息队列、分布式协调服务等
  - **控制器:** `StatefulSet`
  - **特点:** 每个Pod都有独一无二的、稳定的身份（"宠物"）
  - **网络:** 必须配合`Headless Service`，为每个Pod提供稳定的、可单独访问的DNS记录
  - **存储:** 通过`volumeClaimTemplates`为每个Pod自动创建和绑定一个独立的PVC，实现数据的持久化和隔离

- 讲解PV生命周期状态
- 介绍StatefulSet稳定DNS
- 讲解有状态应用备份（Velero）
- 介绍Headless Service原理
- 讲解MySQL主从Operator

### 4. 思考题及作业题
1. 思考题：为什么说"有状态服务比无状态服务更难管理"？具体难在哪里？
2. 作业题：设计一个MySQL主从复制集群的部署方案，使用StatefulSet和适当的初始化脚本
3. 思考题：如何处理有状态应用的备份和恢复？这与无状态应用有何不同？

### 5. 课堂小结
通过本次课程，学生应该能够：
- 理解无状态服务和有状态服务的本质区别
- 掌握StatefulSet的高级特性和使用方法
- 了解有状态服务的存储和网络管理策略
- 能够为不同类型的应用选择合适的部署模式

---

## 第十六周: 服务发现与DevOps实践（理论1学时, 实验1学时）

### 1. 教学目的与要求
- 掌握Kubernetes中的服务发现机制
- 理解内部和外部服务访问的不同方式
- 了解DevOps在Kubernetes环境中的实践

### 2. 教学重点难点
**重点：**
- Service和Ingress的配置和使用
- CI/CD流水线与Kubernetes的集成

**难点：**
- 复杂路由规则的设计
- 多环境发布策略

### 3. 教学过程
#### (1) 理论部分（45分钟）
- **导入环节**：提出核心问题（10分钟）
  - 提问："我的微服务部署在K8s集群内部，它们之间如何相互发现和调用？同时，我如何将前端Web服务暴露给公网用户访问？"
  
- **新课讲授**：服务发现的两面性（35分钟）
  - 讲解**内部服务发现:** 重温`Service`资源，它是K8s内部服务通信的基石。客户端通过稳定的Service DNS名称访问，K8s负责将请求转发到后端健康的Pod
  - 讲解**外部服务发现:** 重温`Ingress`资源，它是从集群外部访问内部HTTP/S服务的标准和推荐方式。`Ingress`作为流量入口，可以根据域名、路径等规则，将请求智能路由到不同的内部`Service`。`LoadBalancer`类型的Service是另一种方式，但成本更高
  - 介绍Jenkins Pipeline语法
  - 讲解Harbor镜像推送
  - 介绍GitLab CI/CD集成
  - 讲解多环境发布策略

#### (2) 实验部分（45分钟）
- **动手实践**：服务发现与访问
  - 部署两个内部服务：`api-service`和`user-service`
  - 让`api-service`通过`user-service`的`ClusterIP` Service名称来调用它
  - 创建一个`Ingress`资源，配置当用户访问`app.yourdomain.com/api`时，流量被转发到`api-service`
  - 在本地配置hosts文件或使用真实域名，通过浏览器或`curl`验证从外部可以成功访问到`api-service`

### 4. 思考题及作业题
1. 思考题：为什么Kubernetes需要同时提供Service和Ingress两种资源？它们各自解决什么问题？
2. 作业题：设计一个完整的CI/CD流水线，包括代码提交、构建、测试、部署到Kubernetes的全过程
3. 思考题：如何实现蓝绿部署或金丝雀发布的自动化流程？

### 5. 课堂小结
通过本次课程，学生应该能够：
- 掌握Kubernetes中的服务发现机制
- 理解内部和外部服务访问的不同方式
- 了解DevOps在Kubernetes环境中的实践
- 能够设计和实现完整的服务访问和发布流程